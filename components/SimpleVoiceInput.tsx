// components/SimpleVoiceInput.tsx - í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ìŒì„± ì…ë ¥

import React, { useState, useRef } from 'react';

interface SimpleVoiceInputProps {
  onTextReceived: (text: string) => void;
  isDisabled?: boolean;
  className?: string;
}

const SimpleVoiceInput: React.FC<SimpleVoiceInputProps> = ({
  onTextReceived,
  isDisabled = false,
  className = '',
}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [error, setError] = useState<string>('');

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  const startRecording = async () => {
    try {
      setError('');

      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
        },
      });

      // MediaRecorder ì„¤ì •
      const options = { mimeType: 'audio/webm' };
      if (!MediaRecorder.isTypeSupported(options.mimeType)) {
        options.mimeType = 'audio/mp4';
      }
      if (!MediaRecorder.isTypeSupported(options.mimeType)) {
        options.mimeType = '';
      }

      const mediaRecorder = new MediaRecorder(stream, options);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log('ğŸ“¦ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì§‘:', event.data.size, 'bytes');
        }
      };

      mediaRecorder.onstop = () => {
        console.log('â¹ï¸ ë…¹ìŒ ì¤‘ì§€ë¨, ì´ ì²­í¬:', audioChunksRef.current.length);
        processAudio();
      };

      // ë…¹ìŒ ì‹œì‘
      mediaRecorder.start(250); // 250msë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘
      setIsRecording(true);
      console.log('ğŸ¤ ë…¹ìŒ ì‹œì‘ë¨');
    } catch (err) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', err);
      setError('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”');
    }
  };

  const stopRecording = () => {
    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state === 'recording'
    ) {
      mediaRecorderRef.current.stop();

      // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
      mediaRecorderRef.current.stream
        .getTracks()
        .forEach((track) => track.stop());

      setIsRecording(false);
      setIsProcessing(true);
    }
  };

  const processAudio = async () => {
    try {
      console.log(
        'ğŸµ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘, ì²­í¬ ê°œìˆ˜:',
        audioChunksRef.current.length,
      );

      if (audioChunksRef.current.length === 0) {
        throw new Error('ë…¹ìŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤');
      }

      // Blob ìƒì„±
      const audioBlob = new Blob(audioChunksRef.current, {
        type: 'audio/webm',
      });

      console.log('ğŸ“„ Blob ìƒì„±ë¨:', {
        size: audioBlob.size,
        type: audioBlob.type,
      });

      if (audioBlob.size === 0) {
        throw new Error('ë…¹ìŒ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');
      }

      // STT API í˜¸ì¶œ
      const formData = new FormData();
      const file = new File([audioBlob], 'recording.webm', {
        type: 'audio/webm',
      });
      formData.append('audio', file);

      console.log('ğŸ“¤ STT API í˜¸ì¶œ ì¤‘...');

      const response = await fetch('/api/stt', {
        method: 'POST',
        body: formData,
      });

      const result = await response.json();
      console.log('ğŸ“¥ STT ì‘ë‹µ:', result);

      if (!response.ok) {
        throw new Error(result.message || 'STT ì²˜ë¦¬ ì‹¤íŒ¨');
      }

      if (result.code === 200 && result.data?.text) {
        console.log('âœ… ìŒì„± ì¸ì‹ ì„±ê³µ:', result.data.text);
        onTextReceived(result.data.text);
        setError('');
      } else {
        throw new Error('ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
      }
    } catch (err) {
      console.error('âŒ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨:', err);
      setError(err instanceof Error ? err.message : 'ì²˜ë¦¬ ì‹¤íŒ¨');
    } finally {
      setIsProcessing(false);
    }
  };

  const handleClick = () => {
    if (isDisabled || isProcessing) return;

    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  const getButtonStyle = () => {
    if (isDisabled) return 'bg-gray-300 text-gray-500 cursor-not-allowed';
    if (isProcessing) return 'bg-blue-500 text-white';
    if (isRecording) return 'bg-red-500 text-white animate-pulse';
    return 'bg-gray-100 hover:bg-gray-200 text-gray-700';
  };

  const getButtonText = () => {
    if (isProcessing) return 'ğŸ”„';
    if (isRecording) return 'â¹ï¸';
    return 'ğŸ¤';
  };

  const getStatusText = () => {
    if (isProcessing) return 'ìŒì„± ë³€í™˜ ì¤‘...';
    if (isRecording) return 'ë…¹ìŒ ì¤‘ (í´ë¦­í•˜ì—¬ ì¤‘ì§€)';
    if (error) return error;
    return 'ìŒì„± ì…ë ¥';
  };

  return (
    <div className="relative">
      <button
        type="button"
        onClick={handleClick}
        disabled={isDisabled}
        className={`w-12 h-12 rounded-lg flex items-center justify-center transition-all duration-200 ${getButtonStyle()} ${className}`}
        title={getStatusText()}
      >
        <span className="text-xl">{getButtonText()}</span>
      </button>

      {/* ìƒíƒœ í‘œì‹œ */}
      {(isRecording || isProcessing || error) && (
        <div
          className={`absolute top-full left-1/2 transform -translate-x-1/2 mt-2 px-3 py-1 rounded-lg text-xs whitespace-nowrap z-10 ${
            error
              ? 'bg-red-500 text-white'
              : isProcessing
              ? 'bg-blue-500 text-white'
              : 'bg-black bg-opacity-75 text-white'
          }`}
        >
          {getStatusText()}
        </div>
      )}
    </div>
  );
};

export default SimpleVoiceInput;
