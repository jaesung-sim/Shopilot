// components/VoiceInput.tsx - ì‹¤ì œ ìŒì„± ì¸ì‹ í™œì„±í™” ìˆ˜ì •
import React, { useState, useRef, useEffect } from 'react';

interface VoiceInputProps {
  onVoiceResult: (text: string) => void;
  disabled?: boolean;
  placeholder?: string;
}

const VoiceInput: React.FC<VoiceInputProps> = ({
  onVoiceResult,
  disabled = false,
  placeholder = 'ìŒì„± ì¸ì‹ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§ì”€í•˜ì„¸ìš”',
}) => {
  const [isListening, setIsListening] = useState(false);
  const [currentTranscript, setCurrentTranscript] = useState('');
  const [error, setError] = useState('');
  const [isSupported, setIsSupported] = useState(false);

  const recognitionRef = useRef<SpeechRecognition | null>(null);

  // Web Speech API ì´ˆê¸°í™” ë° ì§€ì› í™•ì¸
  useEffect(() => {
    console.log('ğŸ” Web Speech API ì§€ì› í™•ì¸...');

    // ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ì²´í¬
    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) {
      console.error('âŒ Web Speech API ì§€ì›ë˜ì§€ ì•ŠìŒ');
      setError(
        'ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chromeì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.',
      );
      setIsSupported(false);
      return;
    }

    console.log('âœ… Web Speech API ì§€ì›ë¨');
    setIsSupported(true);

    // SpeechRecognition ê°ì²´ ìƒì„±
    try {
      recognitionRef.current = new SpeechRecognition();
      setupSpeechRecognition();
    } catch (initError) {
      console.error('âŒ SpeechRecognition ì´ˆê¸°í™” ì‹¤íŒ¨:', initError);
      setError('ìŒì„± ì¸ì‹ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      setIsSupported(false);
    }

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    return () => {
      if (recognitionRef.current) {
        try {
          recognitionRef.current.abort();
        } catch (err) {
          console.warn('SpeechRecognition ì •ë¦¬ ì¤‘ ì˜¤ë¥˜:', err);
        }
      }
    };
  }, []);

  // SpeechRecognition ì„¤ì • ë° ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
  const setupSpeechRecognition = () => {
    if (!recognitionRef.current) return;

    const recognition = recognitionRef.current;

    // ğŸ”§ ì¤‘ìš”: ì‹¤ì œ ìŒì„± ì¸ì‹ ì„¤ì •
    recognition.continuous = false; // í•œ ë²ˆë§Œ ì¸ì‹
    recognition.interimResults = true; // ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ
    recognition.lang = 'ko-KR'; // í•œêµ­ì–´ ì„¤ì •
    recognition.maxAlternatives = 1; // ìµœëŒ€ ëŒ€ì•ˆ ìˆ˜

    console.log('ğŸ¤ SpeechRecognition ì„¤ì • ì™„ë£Œ:', {
      lang: recognition.lang,
      continuous: recognition.continuous,
      interimResults: recognition.interimResults,
    });

    // ìŒì„± ì¸ì‹ ì‹œì‘ ì´ë²¤íŠ¸
    recognition.onstart = () => {
      console.log('ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘ë¨');
      setIsListening(true);
      setError('');
      setCurrentTranscript('');
    };

    // ğŸ”§ í•µì‹¬: ì‹¤ì œ ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬
    recognition.onresult = (event: SpeechRecognitionEvent) => {
      console.log('ğŸ“ ìŒì„± ì¸ì‹ ì´ë²¤íŠ¸ ìˆ˜ì‹ :', event);

      let interimTranscript = '';
      let finalTranscript = '';

      // ëª¨ë“  ê²°ê³¼ ì²˜ë¦¬
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const transcript = result[0].transcript;
        const confidence = result[0].confidence;

        console.log(`ê²°ê³¼ ${i}:`, {
          transcript: transcript,
          confidence: confidence,
          isFinal: result.isFinal,
        });

        if (result.isFinal) {
          finalTranscript += transcript;
          console.log('âœ… ìµœì¢… ìŒì„± ì¸ì‹ ê²°ê³¼:', transcript);
        } else {
          interimTranscript += transcript;
          console.log('â³ ì¤‘ê°„ ìŒì„± ì¸ì‹ ê²°ê³¼:', transcript);
        }
      }

      // ì‹¤ì‹œê°„ ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ
      setCurrentTranscript(interimTranscript);

      // ğŸ”§ ìµœì¢… ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬
      if (finalTranscript.trim()) {
        console.log('ğŸ¯ STT ê²°ê³¼:', finalTranscript.trim());
        // âœ… ìˆ˜ì • (ì•ˆì „í•œ í˜¸ì¶œ)
        if (onVoiceResult && typeof onVoiceResult === 'function') {
          onVoiceResult(finalTranscript.trim());
        } else {
          console.warn('âš ï¸ onVoiceResult ì½œë°±ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
        } // âœ… ì‹¤ì œ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì „ë‹¬
      }
    };

    // ì˜¤ë¥˜ ì²˜ë¦¬
    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      console.error('âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
      setIsListening(false);

      let errorMessage = '';
      switch (event.error) {
        case 'not-allowed':
          errorMessage =
            'ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
          break;
        case 'no-speech':
          errorMessage = 'ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
          break;
        case 'audio-capture':
          errorMessage =
            'ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.';
          break;
        case 'network':
          errorMessage =
            'ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
          break;
        default:
          errorMessage = `ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${event.error}`;
      }
      setError(errorMessage);
    };

    // ìŒì„± ì¸ì‹ ì¢…ë£Œ ì´ë²¤íŠ¸
    recognition.onend = () => {
      console.log('ğŸ”š ìŒì„± ì¸ì‹ ì¢…ë£Œë¨');
      setIsListening(false);
      setCurrentTranscript('');
    };

    // ìŒì„± ê°ì§€ ì‹œì‘
    recognition.onspeechstart = () => {
      console.log('ğŸ—£ï¸ ìŒì„± ê°ì§€ ì‹œì‘');
    };

    // ìŒì„± ê°ì§€ ì¢…ë£Œ
    recognition.onspeechend = () => {
      console.log('ğŸ¤ ìŒì„± ê°ì§€ ì¢…ë£Œ');
    };
  };

  // ìŒì„± ì¸ì‹ ì‹œì‘
  const startListening = async () => {
    if (!recognitionRef.current || !isSupported || disabled) {
      console.warn('âš ï¸ ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŒ:', {
        hasRecognition: !!recognitionRef.current,
        isSupported: isSupported,
        disabled: disabled,
      });
      return;
    }

    try {
      // ë§ˆì´í¬ ê¶Œí•œ ë¨¼ì € í™•ì¸
      console.log('ğŸ¯ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­...');
      await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log('âœ… ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ë¨');

      // ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
      if (isListening) {
        console.warn('âš ï¸ ì´ë¯¸ ìŒì„± ì¸ì‹ì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤');
        return;
      }

      setError('');
      console.log('ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘ ìš”ì²­...');
      recognitionRef.current.start();
    } catch (permissionError) {
      console.error('âŒ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€:', permissionError);
      setError(
        'ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì €ì—ì„œ ë§ˆì´í¬ ì ‘ê·¼ì„ í—ˆìš©í•´ì£¼ì„¸ìš”.',
      );
    }
  };

  // ìŒì„± ì¸ì‹ ì¤‘ì§€
  const stopListening = () => {
    if (recognitionRef.current && isListening) {
      console.log('â¹ï¸ ìŒì„± ì¸ì‹ ì¤‘ì§€ ìš”ì²­...');
      recognitionRef.current.stop();
    }
  };

  // ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì € ì²˜ë¦¬
  if (!isSupported) {
    return (
      <div className="flex items-center gap-2">
        <button
          disabled
          className="p-2 rounded-full bg-gray-400 text-white cursor-not-allowed"
          title="ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
        >
          ğŸ¤
        </button>
        <div className="text-sm text-red-600">
          {error || 'ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤'}
        </div>
      </div>
    );
  }

  return (
    <div className="flex items-center gap-2">
      {/* ìŒì„± ì¸ì‹ ë²„íŠ¼ */}
      <button
        onClick={isListening ? stopListening : startListening}
        disabled={disabled}
        className={`p-2 rounded-full transition-all duration-200 ${
          isListening
            ? 'bg-red-500 hover:bg-red-600 animate-pulse text-white'
            : 'bg-blue-500 hover:bg-blue-600 text-white'
        } disabled:bg-gray-400 disabled:cursor-not-allowed`}
        title={isListening ? 'ìŒì„± ì¸ì‹ ì¤‘ì§€' : 'ìŒì„± ì¸ì‹ ì‹œì‘'}
      >
        {isListening ? 'ğŸ”´' : 'ğŸ¤'}
      </button>

      {/* ì‹¤ì‹œê°„ ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ */}
      {currentTranscript && (
        <div className="bg-yellow-50 border border-yellow-200 rounded px-3 py-1 text-sm">
          <span className="text-yellow-700">
            <strong>ì¸ì‹ ì¤‘:</strong> "{currentTranscript}"
          </span>
        </div>
      )}

      {/* ì˜¤ë¥˜ ë©”ì‹œì§€ */}
      {error && (
        <div className="bg-red-50 border border-red-200 rounded px-3 py-1 text-sm">
          <span className="text-red-700">{error}</span>
        </div>
      )}

      {/* ìƒíƒœ í‘œì‹œ */}
      {isListening && !currentTranscript && (
        <div className="flex items-center gap-1 text-sm text-blue-600">
          <div className="w-2 h-2 bg-red-500 rounded-full animate-ping"></div>
          <span>ë“£ê³  ìˆìŠµë‹ˆë‹¤...</span>
        </div>
      )}
    </div>
  );
};

export default VoiceInput;

// ğŸ”§ ì‚¬ìš©ë²• ì˜ˆì‹œ (ChatBot.tsxì—ì„œ)
/*
import VoiceInput from './VoiceInput';

// ChatBot ì»´í¬ë„ŒíŠ¸ ë‚´ë¶€ì—ì„œ
const handleVoiceInput = (recognizedText: string) => {
  console.log('ğŸ¯ ìŒì„±ìœ¼ë¡œ ì…ë ¥ëœ í…ìŠ¤íŠ¸:', recognizedText);
  setMessage(recognizedText); // ì…ë ¥ í•„ë“œì— ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì„¤ì •
};

// JSXì—ì„œ ì‚¬ìš©
<div className="flex gap-2">
  <input
    type="text"
    value={message}
    onChange={(e) => setMessage(e.target.value)}
    placeholder="ì˜ˆ: ë°”ë‚˜ë‚˜, ì‚¬ê³¼, ìš°ìœ , ë¹µ, ë¼ì§€ê³ ê¸° ì‚¬ê³ ì‹¶ì–´"
    className="flex-1 border rounded-lg px-4 py-2"
  />
  <VoiceInput 
    onVoiceResult={handleVoiceInput}
    disabled={isLoading}
  />
  <button type="submit">ì „ì†¡</button>
</div>
*/
