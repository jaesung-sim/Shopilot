// lib/audioUtils.ts - ìŒì„± ë…¹ìŒ ë° ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°

export interface AudioRecorderConfig {
  sampleRate?: number;
  channels?: number;
  bitRate?: number;
  maxDuration?: number; // ì´ˆ ë‹¨ìœ„
  mimeType?: string;
}

export interface RecordingState {
  isRecording: boolean;
  isPaused: boolean;
  duration: number;
  audioLevel: number;
}

export class AudioRecorder {
  private mediaRecorder: MediaRecorder | null = null;
  private audioStream: MediaStream | null = null;
  private audioChunks: Blob[] = [];
  private config: Required<AudioRecorderConfig>;
  private onStateChange?: (state: RecordingState) => void;
  private onError?: (error: Error) => void;

  // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë ˆë²¨ ì¸¡ì •ìš©
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private audioLevelInterval: NodeJS.Timeout | null = null;

  // ìƒíƒœ ê´€ë¦¬
  private state: RecordingState = {
    isRecording: false,
    isPaused: false,
    duration: 0,
    audioLevel: 0,
  };

  constructor(config: AudioRecorderConfig = {}) {
    this.config = {
      sampleRate: config.sampleRate || 16000,
      channels: config.channels || 1,
      bitRate: config.bitRate || 128000,
      maxDuration: config.maxDuration || 60, // ê¸°ë³¸ 60ì´ˆ
      mimeType: config.mimeType || this.getOptimalMimeType(),
    };
  }

  // ë¸Œë¼ìš°ì €ë³„ ìµœì  MIME íƒ€ì… ì„ íƒ
  private getOptimalMimeType(): string {
    const types = [
      'audio/webm;codecs=opus',
      'audio/webm',
      'audio/mp4',
      'audio/wav',
    ];

    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) {
        console.log('ğŸµ ì„ íƒëœ ì˜¤ë””ì˜¤ í˜•ì‹:', type);
        return type;
      }
    }

    console.warn('âš ï¸ ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©');
    return 'audio/webm';
  }

  // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
  public setOnStateChange(callback: (state: RecordingState) => void): void {
    this.onStateChange = callback;
  }

  public setOnError(callback: (error: Error) => void): void {
    this.onError = callback;
  }

  // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ë° ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
  public async initialize(): Promise<void> {
    try {
      console.log('ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­...');

      // ë¸Œë¼ìš°ì € ì§€ì› í™•ì¸
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('ë¸Œë¼ìš°ì €ê°€ ìŒì„± ë…¹ìŒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤');
      }

      if (!MediaRecorder) {
        throw new Error('ë¸Œë¼ìš°ì €ê°€ MediaRecorderë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤');
      }

      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      this.audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: this.config.sampleRate,
          channelCount: this.config.channels,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      console.log('âœ… ë§ˆì´í¬ ê¶Œí•œ íšë“ ì„±ê³µ');

      // ì˜¤ë””ì˜¤ ë ˆë²¨ ì¸¡ì •ì„ ìœ„í•œ AudioContext ì„¤ì •
      this.setupAudioLevelMonitoring();

      // MediaRecorder ì´ˆê¸°í™”
      this.mediaRecorder = new MediaRecorder(this.audioStream, {
        mimeType: this.config.mimeType,
        audioBitsPerSecond: this.config.bitRate,
      });

      this.setupMediaRecorderEvents();
    } catch (error) {
      console.error('âŒ ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);

      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          throw new Error(
            'ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.',
          );
        } else if (error.name === 'NotFoundError') {
          throw new Error('ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        } else if (error.name === 'NotReadableError') {
          throw new Error('ë§ˆì´í¬ê°€ ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.');
        }
      }

      throw error;
    }
  }

  // ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì„¤ì •
  private setupAudioLevelMonitoring(): void {
    if (!this.audioStream) return;

    try {
      this.audioContext = new AudioContext();
      const source = this.audioContext.createMediaStreamSource(
        this.audioStream,
      );
      this.analyser = this.audioContext.createAnalyser();

      this.analyser.fftSize = 256;
      source.connect(this.analyser);
    } catch (error) {
      console.warn('âš ï¸ ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì‹¤íŒ¨:', error);
    }
  }

  // MediaRecorder ì´ë²¤íŠ¸ ì„¤ì •
  private setupMediaRecorderEvents(): void {
    if (!this.mediaRecorder) return;

    this.mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        this.audioChunks.push(event.data);
        console.log('ğŸµ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ :', event.data.size, 'bytes');
      }
    };

    this.mediaRecorder.onstart = () => {
      console.log('ğŸ¤ ë…¹ìŒ ì‹œì‘');
      this.state.isRecording = true;
      this.state.isPaused = false;
      this.updateState();
      this.startAudioLevelMonitoring();
      this.startDurationTimer();
    };

    this.mediaRecorder.onstop = () => {
      console.log('â¹ï¸ ë…¹ìŒ ì¤‘ì§€');
      this.state.isRecording = false;
      this.state.isPaused = false;
      this.updateState();
      this.stopAudioLevelMonitoring();
      this.stopDurationTimer();
    };

    this.mediaRecorder.onpause = () => {
      console.log('â¸ï¸ ë…¹ìŒ ì¼ì‹œì •ì§€');
      this.state.isPaused = true;
      this.updateState();
    };

    this.mediaRecorder.onresume = () => {
      console.log('â–¶ï¸ ë…¹ìŒ ì¬ê°œ');
      this.state.isPaused = false;
      this.updateState();
    };

    this.mediaRecorder.onerror = (event) => {
      console.error('âŒ ë…¹ìŒ ì˜¤ë¥˜:', event);
      const error = new Error('ìŒì„± ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤');
      this.onError?.(error);
    };
  }

  // ë…¹ìŒ ì‹œì‘
  public async startRecording(): Promise<void> {
    if (!this.mediaRecorder) {
      await this.initialize();
    }

    if (this.mediaRecorder?.state === 'recording') {
      console.warn('âš ï¸ ì´ë¯¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤');
      return;
    }

    try {
      this.audioChunks = [];
      this.state.duration = 0;

      this.mediaRecorder?.start(100); // 100msë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘
    } catch (error) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
      const recordingError = new Error('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
      this.onError?.(recordingError);
      throw recordingError;
    }
  }

  // ë…¹ìŒ ì¤‘ì§€ ë° Blob ë°˜í™˜
  public async stopRecording(): Promise<Blob> {
    return new Promise((resolve, reject) => {
      if (!this.mediaRecorder || this.mediaRecorder.state === 'inactive') {
        reject(new Error('ë…¹ìŒì´ ì§„í–‰ ì¤‘ì´ì§€ ì•ŠìŠµë‹ˆë‹¤'));
        return;
      }

      const handleStop = () => {
        console.log(
          'ğŸµ MediaRecorder ì¤‘ì§€ ì´ë²¤íŠ¸ ë°œìƒ, ì²­í¬ ê°œìˆ˜:',
          this.audioChunks.length,
        );

        if (this.audioChunks.length === 0) {
          reject(new Error('ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'));
          return;
        }

        try {
          const audioBlob = new Blob(this.audioChunks, {
            type: this.config.mimeType,
          });

          console.log('âœ… ì˜¤ë””ì˜¤ Blob ìƒì„± ì„±ê³µ:', {
            size: audioBlob.size,
            type: audioBlob.type,
            chunks: this.audioChunks.length,
            mimeType: this.config.mimeType,
          });

          // ìµœì†Œ í¬ê¸° ì²´í¬ (ë§¤ìš° ì‘ì€ íŒŒì¼ì€ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŒ)
          if (audioBlob.size < 100) {
            reject(
              new Error('ë…¹ìŒëœ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'),
            );
            return;
          }

          resolve(audioBlob);
        } catch (blobError) {
          console.error('âŒ Blob ìƒì„± ì˜¤ë¥˜:', blobError);
          reject(new Error('ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤'));
        }
      };

      this.mediaRecorder.addEventListener('stop', handleStop, { once: true });

      try {
        this.mediaRecorder.stop();
      } catch (stopError) {
        console.error('âŒ MediaRecorder ì¤‘ì§€ ì˜¤ë¥˜:', stopError);
        reject(new Error('ë…¹ìŒ ì¤‘ì§€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤'));
      }
    });
  }

  // ì¼ì‹œì •ì§€/ì¬ê°œ
  public pauseRecording(): void {
    if (this.mediaRecorder?.state === 'recording') {
      this.mediaRecorder.pause();
    }
  }

  public resumeRecording(): void {
    if (this.mediaRecorder?.state === 'paused') {
      this.mediaRecorder.resume();
    }
  }

  // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§
  private startAudioLevelMonitoring(): void {
    if (!this.analyser) return;

    this.audioLevelInterval = setInterval(() => {
      if (!this.analyser) return;

      const dataArray = new Uint8Array(this.analyser.frequencyBinCount);
      this.analyser.getByteFrequencyData(dataArray);

      // í‰ê·  ì˜¤ë””ì˜¤ ë ˆë²¨ ê³„ì‚° (0-100)
      const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
      this.state.audioLevel = Math.round((average / 255) * 100);

      this.updateState();
    }, 100);
  }

  private stopAudioLevelMonitoring(): void {
    if (this.audioLevelInterval) {
      clearInterval(this.audioLevelInterval);
      this.audioLevelInterval = null;
    }
    this.state.audioLevel = 0;
  }

  // ë…¹ìŒ ì‹œê°„ íƒ€ì´ë¨¸
  private durationTimer: NodeJS.Timeout | null = null;

  private startDurationTimer(): void {
    this.durationTimer = setInterval(() => {
      if (this.state.isRecording && !this.state.isPaused) {
        this.state.duration += 0.1;

        // ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ì²´í¬
        if (this.state.duration >= this.config.maxDuration) {
          console.log('â° ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ë„ë‹¬, ìë™ ì¤‘ì§€');
          this.stopRecording().catch(console.error);
        }

        this.updateState();
      }
    }, 100);
  }

  private stopDurationTimer(): void {
    if (this.durationTimer) {
      clearInterval(this.durationTimer);
      this.durationTimer = null;
    }
  }

  // ìƒíƒœ ì—…ë°ì´íŠ¸ ì•Œë¦¼
  private updateState(): void {
    this.onStateChange?.(this.state);
  }

  // í˜„ì¬ ìƒíƒœ ë°˜í™˜
  public getState(): RecordingState {
    return { ...this.state };
  }

  // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  public cleanup(): void {
    console.log('ğŸ§¹ AudioRecorder ë¦¬ì†ŒìŠ¤ ì •ë¦¬');

    // ë…¹ìŒ ì¤‘ì§€
    if (this.mediaRecorder?.state === 'recording') {
      this.mediaRecorder.stop();
    }

    // íƒ€ì´ë¨¸ ì •ë¦¬
    this.stopAudioLevelMonitoring();
    this.stopDurationTimer();

    // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
    if (this.audioStream) {
      this.audioStream.getTracks().forEach((track) => {
        track.stop();
        console.log('ğŸ¤ ì˜¤ë””ì˜¤ íŠ¸ë™ ì¤‘ì§€:', track.kind);
      });
      this.audioStream = null;
    }

    // AudioContext ì •ë¦¬
    if (this.audioContext?.state !== 'closed') {
      this.audioContext?.close();
      this.audioContext = null;
    }

    // ìƒíƒœ ì´ˆê¸°í™”
    this.state = {
      isRecording: false,
      isPaused: false,
      duration: 0,
      audioLevel: 0,
    };

    this.mediaRecorder = null;
    this.analyser = null;
    this.audioChunks = [];
  }
}

// STT ì„œë¹„ìŠ¤ í•¨ìˆ˜
export async function sendAudioToSTT(audioBlob: Blob): Promise<string> {
  console.log('ğŸ“¤ STT API í˜¸ì¶œ ì‹œì‘:', {
    size: audioBlob.size,
    type: audioBlob.type,
  });

  // ì˜¤ë””ì˜¤ íŒŒì¼ í¬ê¸° ì²´í¬
  if (audioBlob.size === 0) {
    throw new Error('ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤');
  }

  if (audioBlob.size > 25 * 1024 * 1024) {
    // 25MB ì œí•œ
    throw new Error('ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ (ìµœëŒ€ 25MB)');
  }

  try {
    const formData = new FormData();

    // íŒŒì¼ëª…ê³¼ MIME íƒ€ì…ì„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
    const fileName = 'recording.webm';
    const file = new File([audioBlob], fileName, {
      type: audioBlob.type || 'audio/webm',
    });

    formData.append('audio', file);

    console.log('ğŸ“¤ FormData êµ¬ì„± ì™„ë£Œ:', {
      fileName: fileName,
      fileSize: file.size,
      fileType: file.type,
    });

    const response = await fetch('/api/stt', {
      method: 'POST',
      body: formData,
    });

    console.log('ğŸ“¥ STT API ì‘ë‹µ ìƒíƒœ:', response.status);

    const result = await response.json();
    console.log('ğŸ“¥ STT API ì‘ë‹µ ë°ì´í„°:', result);

    if (!response.ok) {
      throw new Error(result.message || `STT API ì˜¤ë¥˜: ${response.status}`);
    }

    if (result.code !== 200 || !result.data?.text) {
      throw new Error(result.message || 'ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤');
    }

    console.log('âœ… STT ì„±ê³µ:', result.data.text);
    return result.data.text;
  } catch (error) {
    console.error('âŒ STT ì‹¤íŒ¨:', error);

    // ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì²˜ë¦¬
    if (error instanceof TypeError && error.message.includes('fetch')) {
      throw new Error('ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”');
    }

    throw error instanceof Error
      ? error
      : new Error('STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤');
  }
}

// ì˜¤ë””ì˜¤ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
export function formatDuration(seconds: number): string {
  const mins = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  return `${mins}:${secs.toString().padStart(2, '0')}`;
}

export function getAudioLevelColor(level: number): string {
  if (level < 20) return '#10b981'; // ì´ˆë¡
  if (level < 60) return '#f59e0b'; // ë…¸ë‘
  return '#ef4444'; // ë¹¨ê°•
}
